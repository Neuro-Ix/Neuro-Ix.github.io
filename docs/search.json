[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Neuro-iX is run by Sylvain Bouix. This brand new lab revolves around developing robust softwares to analyse brain imaging and behavioral data for the study of mental disorders in particular schizophrenia, brain injury and chronic traumatic encephalopathy.\nWe advocate open science practices and the development of health technologies that are less biased, more inclusive and equitable.\n\n\nNew recruitment phase for 2025 !\nWe are currently recruiting talented PhD applicants for the Winter 2025 or Summer 2025 sessions to work on neuroimaging projects including brain segmentation, diffusion MRI processing and more !\nApplicants are asked to prepare a CV, a cover letter and fill out this online form by October 31st 2024.\nWe will consider outstanding applicants on a rolling basis for MSc and postdoctoral positions. Undergraduate and high school students are also welcome for short- and medium- term internships. We are committed to building a diverse environment.\nClick here for the online form"
  },
  {
    "objectID": "presentations/posts/2024_03_11_CB_FetMRQC/index.html",
    "href": "presentations/posts/2024_03_11_CB_FetMRQC/index.html",
    "title": "Presentation of FET-MRQC",
    "section": "",
    "text": "Abstract of the article:\nQuality control (QC) has long been considered essential to guarantee the reliability of neuroimaging studies. It is particularly important for fetal brain MRI, where large and unpredictable fetal motion can lead to substantial artifacts in the acquired images. Existing methods for fetal brain quality assessment operate at the slice level, and fail to get a comprehensive picture of the quality of an image, that can only be achieved by looking at the entire brain volume. In this work, we propose FetMRQC, a machine learning framework for automated image quality assessment tailored to fetal brain MRI, which extracts an ensemble of quality metrics that are then used to predict experts’ ratings. Based on the manual ratings of more than 1000 low-resolution stacks acquired across two different institutions, we show that, compared with existing quality metrics, FetMRQC is able to generalize out-of-domain, while being interpretable and data efficient. We also release a novel manual quality rating tool designed to facilitate and optimize quality rating of fetal brain images. Our tool, along with all the code to generate, train and evaluate the model is available at https://github.com/Medical-Image-Analysis-Laboratory/fetal_brain_qc/."
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Neuro-iX",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDevelopment of the PSYCHS: Positive SYmptoms and Diagnostic Criteria for the CAARMS Harmonized with the SIPS\n\n\n\n\n\n\nascertainment\n\n\nclinical high risk\n\n\nearly detection\n\n\npsychometrics\n\n\nseverity rating\n\n\n\nPMID: 37641537 DOI: 10.1111/eip.13457\n\n\n\n\n\n2023-08-28\n\n\nScott W Woods, Sophie Parker, Melissa J Kerr, Barbara C Walsh, S Andrea Wijtenburg, Nicholas Prunier, Angela R Nunez, Kate Buccilli, Catalina Mourgues-Codern, Kali Brummitt, Kyle S Kinney, Carli Trankler, Julia Szacilo, Beau-Luke Colton, Munaza Ali, Anastasia Haidar, Tashrif Billah, Kevin Huynh, Uzair Ahmed, Laura L Adery, Patricia J Marcy, Kelly Allott, Paul Amminger, Celso Arango, Matthew R Broome, … …\n\n\n\n\n\n\n\nAdverse Outcome Following Mild Traumatic Brain Injury Is Associated with Microstructure Alterations at the Gray and White Matter Boundary\n\n\n\n\n\n\ncognitive impairment\n\n\ndiffusion tensor imaging\n\n\nfractional anisotropy\n\n\nmagnetic resonance imaging\n\n\nmild traumatic brain injury\n\n\npost-concussion symptoms\n\n\n\nPMID: 37629457 DOI: 10.3390/jcm12165415\n\n\n\n\n\n2023-08-21\n\n\nLara Pankatz, Philine Rojczyk, Johanna Seitz-Holland, Sylvain Bouix, Leonard B Jung, Tim L T Wiegand, Elena M Bonke, Nico Sollmann, Elisabeth Kaufmann, Holly Carrington, Twishi Puri, Yogesh Rathi, Michael J Coleman, Ofer Pasternak, Mark S George, Thomas W McAllister, Ross Zafonte, Murray B Stein, Christine E Marx, Martha E Shenton, Inga K Koerte\n\n\n\n\n\n\n\nExploring the impact of hippocampal sclerosis on white matter tracts memory in individuals with mesial temporal lobe epilepsy\n\n\n\n\n\n\ncognitive impairment\n\n\nfocal epilepsy\n\n\nmagnetic resonance imaging\n\n\nwhite matter tracts\n\n\n\nPMID: 37469213 DOI: 10.1002/epi4.12793\n\n\n\n\n\n2023-07-19\n\n\nTamires A Zanao, Johanna Seitz-Holland, Lauren J O’Donnell, Fan Zhang, Yogesh Rathi, Tatila M Lopes, Luciana Ramalho Pimentel-Silva, Clarissa L Yassuda, Nikos Makris, Martha E Shenton, Sylvain Bouix, Amanda E Lyall, Fernando Cendes\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/posts/2023_08_28_development_of_the_psychs_positive_symptoms/index.html",
    "href": "publications/posts/2023_08_28_development_of_the_psychs_positive_symptoms/index.html",
    "title": "Development of the PSYCHS: Positive SYmptoms and Diagnostic Criteria for the CAARMS Harmonized with the SIPS",
    "section": "",
    "text": "Abstract:\nAIM: To harmonize two ascertainment and severity rating instruments commonly used for the clinical high risk syndrome for psychosis (CHR-P): the Structured Interview for Psychosis-risk Syndromes (SIPS) and the Comprehensive Assessment of At-Risk Mental States (CAARMS).\nMETHODS: The initial workshop is described in the companion report from Addington et al. After the workshop, lead experts for each instrument continued harmonizing attenuated positive symptoms and criteria for psychosis and CHR-P through an intensive series of joint videoconferences.\nRESULTS: Full harmonization was achieved for attenuated positive symptom ratings and psychosis criteria, and modest harmonization for CHR-P criteria. The semi-structured interview, named Positive SYmptoms and Diagnostic Criteria for the CAARMS Harmonized with the SIPS (PSYCHS), generates CHR-P criteria and severity scores for both CAARMS and SIPS.\nCONCLUSIONS: Using the PSYCHS for CHR-P ascertainment, conversion determination, and attenuated positive symptom severity rating will help in comparing findings across studies and in meta-analyses."
  },
  {
    "objectID": "contact/index.html",
    "href": "contact/index.html",
    "title": "Contact",
    "section": "",
    "text": "If you’re interested in joining the lab, please fill out this form.\nFor all other enquiries email Sylvain Bouix."
  },
  {
    "objectID": "tools/index.html",
    "href": "tools/index.html",
    "title": "Tools",
    "section": "",
    "text": "Neuroimaging tools\nNeuroinformatics for AMP-SCZ\nSlicerNeuroSegmentation"
  },
  {
    "objectID": "tools/index.html#software",
    "href": "tools/index.html#software",
    "title": "Tools",
    "section": "",
    "text": "Neuroimaging tools\nNeuroinformatics for AMP-SCZ\nSlicerNeuroSegmentation"
  },
  {
    "objectID": "tools/index.html#data",
    "href": "tools/index.html#data",
    "title": "Tools",
    "section": "Data",
    "text": "Data\n\nHuman Connectome for Early Psychosis\nHarvard-Oxford Atlas 2.0: Subcortical parcellations"
  },
  {
    "objectID": "presentations/posts/2024_02_08_SD_FD_Net_susceptibility_artifact_correction/index.html",
    "href": "presentations/posts/2024_02_08_SD_FD_Net_susceptibility_artifact_correction/index.html",
    "title": "Presentation of the FD-NET",
    "section": "",
    "text": "Abstract of the article:\nPurpose: To introduce an unsupervised deep-learning method for fast and effective correction of susceptibility artifacts in reversed phase-encode (PE) image pairs acquired with echo planar imaging (EPI).\nMethods: Recent learning-based correction approaches in EPI estimate a displacement field, unwarp the reversed-PE image pair with the estimated field, and average the unwarped pair to yield a corrected image. Unsupervised learning in these unwarping-based methods is commonly attained via a similarity constraint between the unwarped images in reversed-PE directions, neglecting consistency to the acquired EPI images. This work introduces a novel unsupervised deep Forward-Distortion Network (FD-Net) that predicts both the susceptibility-induced displacement field and the underlying anatomically correct image. Unlike previous methods, FD-Net enforces the forward-distortions of the correct image in both PE directions to be consistent with the acquired reversed-PE image pair. FD-Net further leverages a multiresolution architecture to maintain high local and global performance.\nResults: FD-Net performs competitively with a gold-standard reference method (TOPUP) in image quality, while enabling a leap in computational efficiency. Furthermore, FD-Net outperforms recent unwarping-based methods for unsupervised correction in terms of both image and field quality.\nConclusion: The unsupervised FD-Net method introduces a deep forward-distortion approach to enable fast, high-fidelity correction of susceptibility artifacts in EPI by maintaining consistency to measured data. Therefore, it holds great promise for improving the anatomical accuracy of EPI imaging."
  },
  {
    "objectID": "presentations/posts/2024_04_15_BV_midb_atlas/index.html",
    "href": "presentations/posts/2024_04_15_BV_midb_atlas/index.html",
    "title": "Presentation of the MITB functional atlas of the cerebral cortex",
    "section": "",
    "text": "Abstract of the article:\nAlthough the general location of functional neural networks is similar across individuals, there is vast person-to-person topographic variability. To capture this, we implemented precision brain mapping functional magnetic resonance imaging methods to establish an open-source, method-flexible set of precision functional network atlases—the Masonic Institute for the Developing Brain (MIDB) Precision Brain Atlas. This atlas is an evolving resource comprising 53,273 individual-specific network maps, from more than 9,900 individuals, across ages and cohorts, including the Adolescent Brain Cognitive Development study, the Developmental Human Connectome Project and others. We also generated probabilistic network maps across multiple ages and integration zones (using a new overlapping mapping technique, Overlapping MultiNetwork Imaging). Using regions of high network invariance improved the reproducibility of executive function statistical maps in brain-wide associations compared to group average-based parcellations. Finally, we provide a potential use case for probabilistic maps for targeted neuromodulation. The atlas is expandable to alternative datasets with an online interface encouraging the scientific community to explore and contribute to understanding the human brain function more precisely."
  },
  {
    "objectID": "presentations/posts/2024_02_26_KM_cortical_surface_reconstruction_neural_deformation_fields/index.html",
    "href": "presentations/posts/2024_02_26_KM_cortical_surface_reconstruction_neural_deformation_fields/index.html",
    "title": "Presentation of the article ‘Neural deformation fields for template-based reconstruction of cortical surfaces from MRI’",
    "section": "",
    "text": "Abstract of the article:\nThe reconstruction of cortical surfaces is a prerequisite for quantitative analyses of the cerebral cortex in magnetic resonance imaging (MRI). Existing segmentation-based methods separate the surface registration from the surface extraction, which is computationally inefficient and prone to distortions. We introduce Vox2Cortex-Flow (V2C-Flow), a deep mesh-deformation technique that learns a deformation field from a brain template to the cortical surfaces of an MRI scan. To this end, we present a geometric neural network that models the deformation-describing ordinary differential equation in a continuous manner. The network architecture comprises convolutional and graph-convolutional layers, which allows it to work with images and meshes at the same time. V2C-Flow is not only very fast, requiring less than two seconds to infer all four cortical surfaces, but also establishes vertex-wise correspondences to the template during reconstruction. In addition, V2C-Flow is the first approach for cortex reconstruction that models white matter and pial surfaces jointly, therefore avoiding intersections between them. Our comprehensive experiments on internal and external test data demonstrate that V2C-Flow results in cortical surfaces that are state-of-the-art in terms of accuracy. Moreover, we show that the established correspondences are more consistent than in FreeSurfer and that they can directly be utilized for cortex parcellation and group analyses of cortical thickness."
  },
  {
    "objectID": "presentations/posts/2024_02_05_BV_MedSAM/index.html",
    "href": "presentations/posts/2024_02_05_BV_MedSAM/index.html",
    "title": "Presentation of MedSAM",
    "section": "",
    "text": "Abstract of the article:\nMedical image segmentation is a critical component in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring. However, existing methods, often tailored to specific modalities or disease types, lack generalizability across the diverse spectrum of medical image segmentation tasks. Here we present MedSAM, a foundation model designed for bridging this gap by enabling universal medical image segmentation. The model is developed on a large-scale medical image dataset with 1,570,263 image-mask pairs, covering 10 imaging modalities and over 30 cancer types. We conduct a comprehensive evaluation on 86 internal validation tasks and 60 external validation tasks, demonstrating better accuracy and robustness than modality-wise specialist models. By delivering accurate and efficient segmentation across a wide spectrum of tasks, MedSAM holds significant potential to expedite the evolution of diagnostic tools and the personalization of treatment plans."
  },
  {
    "objectID": "presentations/posts/2024_09_09_BV_brainlife_online_platform/index.html",
    "href": "presentations/posts/2024_09_09_BV_brainlife_online_platform/index.html",
    "title": "Presentation of the online platform brainlife.io",
    "section": "",
    "text": "Abstract of the article:\nNeuroscience is advancing standardization and tool development to support rigor and transparency. Consequently, data pipeline complexity has increased, hindering FAIR (findable, accessible, interoperable and reusable) access. brainlife.io was developed to democratize neuroimaging research. The platform provides data standardization, management, visualization and processing and automatically tracks the provenance history of thousands of data objects. Here, brainlife.io is described and evaluated for validity, reliability, reproducibility, replicability and scientific utility using four data modalities and 3,200 participants."
  },
  {
    "objectID": "presentations/index.html",
    "href": "presentations/index.html",
    "title": "Neuro-iX",
    "section": "",
    "text": "Welcome to the weekly Jounal Club, where relevant articles and tools are presented by the Neuro-iX lab !\nIf you are part of ETS, you can find the powerpoints here.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nPresentation of the article ‘Multi-Atlas Segmentation with Joint Label Fusion’\n\n\n\n\n\n\nmulti-atlas\n\n\nmagnetic resonance imaging\n\n\nsegmentation\n\n\njoint label fusion\n\n\n\nDOI: 10.1109/TPAMI.2012.143\n\n\n\n\n\n2024-09-16\n\n\nGhazal Danaee\n\n\n\n\n\n\n\nPresentation of the online platform brainlife.io\n\n\n\n\n\n\nmagnetic resonance imaging\n\n\nneuroimaging\n\n\nonline platform\n\n\nstandardization\n\n\n\nDOI: 10.1038/s41592-024-02237-2\n\n\n\n\n\n2024-09-09\n\n\nBenoît Verreman\n\n\n\n\n\n\n\nPresentation of SimpleClick\n\n\n\n\n\n\nvision transformer\n\n\nclick-based interactive image segmentation\n\n\nmasked autoencoder\n\n\n\nDOI: 10.48550/arXiv.2210.11006\n\n\n\n\n\n2024-05-06\n\n\nGhazal Danaee\n\n\n\n\n\n\n\nPresentation of the MITB functional atlas of the cerebral cortex\n\n\n\n\n\n\nfunctional atlas\n\n\ncortex parcellation\n\n\nmagnetic resonance imaging\n\n\n\nDOI: 10.1038/s41593-024-01596-5\n\n\n\n\n\n2024-04-15\n\n\nBenoît Verreman\n\n\n\n\n\n\n\nPresentation of FET-MRQC\n\n\n\n\n\n\nquality control\n\n\nfetal brain\n\n\nmagnetic resonance imaging\n\n\nT2w\n\n\n\nDOI: 10.48550/arXiv.2304.05879\n\n\n\n\n\n2024-03-11\n\n\nCharles Bricout\n\n\n\n\n\n\n\nPresentation of the article ‘Neural deformation fields for template-based reconstruction of cortical surfaces from MRI’\n\n\n\n\n\n\ngeometric deep learning\n\n\nmagnetic resonance imaging\n\n\ncortical surface reconstruction\n\n\nbrain segmentation\n\n\nregistration\n\n\n\nDOI: 10.48550/arXiv.2401.12938\n\n\n\n\n\n2024-02-26\n\n\nKaveh Moradkhani\n\n\n\n\n\n\n\nPresentation of the article ‘Semi-automatic segmentation of the fetal brain from magnetic resonance imaging’\n\n\n\n\n\n\nmagnetic resonance imaging\n\n\nfetal brain\n\n\nlinear registration\n\n\nnonlinear registration\n\n\nvolumetric reconstruction\n\n\n\nDOI: 10.3389/fnins.2022.1027084\n\n\n\n\n\n2024-02-12\n\n\nGhazal Danaee\n\n\n\n\n\n\n\nPresentation of the FD-NET\n\n\n\n\n\n\ndeep learning\n\n\necho planar imaging\n\n\nreversed phase-encoding\n\n\nsusceptibility artifacts\n\n\nunsupervised learning\n\n\n\nDOI: 10.1002/mrm.29851\n\n\n\n\n\n2024-02-08\n\n\nSedigheh Dargahi\n\n\n\n\n\n\n\nPresentation of MedSAM\n\n\n\n\n\n\nfondation model\n\n\nmedical image segmentation\n\n\n\nDOI: 10.48550/arXiv.2304.12306\n\n\n\n\n\n2024-02-05\n\n\nBenoît Verreman\n\n\n\n\n\n\n\nPresentation of the python library TorchIO\n\n\n\n\n\n\nopen-source\n\n\npython library\n\n\npatch-based sampling\n\n\n3D medical images\n\n\n\nWebsite: https://torchio.readthedocs.io/\n\n\n\n\n\n2024-01-29\n\n\nCharles Bricout\n\n\n\n\n\n\n\nPresentation of the article ‘Robust T-Loss for Medical Image Segmentation’\n\n\n\n\n\n\nrobust loss\n\n\nmedical image segmentation\n\n\nnoisy labels\n\n\n\nDOI: 10.48550/arXiv.2306.00753\n\n\n\n\n\n2024-01-22\n\n\nMélanie Gaillochet\n\n\n\n\n\n\n\nPresentation of the conference paper ‘Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head’\n\n\n\n\n\n\nNadaraya-Watson head\n\n\nmachine learning\n\n\nnonparametric invariant representation\n\n\n\nDOI: 10.48550/arXiv.2309.13377\n\n\n\n\n\n2024-01-15\n\n\nSukesh Adiga\n\n\n\n\n\n\n\nPresentation of FastSurferVINN\n\n\n\n\n\n\nbrain segmentation\n\n\nmagnetic resonance imaging\n\n\nresolution independence\n\n\n\nDOI: 10.1016/j.neuroimage.2022.118933\n\n\n\n\n\n2023-11-22\n\n\nBenoît Verreman\n\n\n\n\n\n\n\nPresentation of NeRF\n\n\n\n\n\n\nscene representation\n\n\nview synthesis\n\n\nimage-based rendering\n\n\nvolume rendering\n\n\n3D deep learning\n\n\n\nDOI: 10.48550/arXiv.2003.08934\n\n\n\n\n\n2023-11-15\n\n\nCharles Bricout\n\n\n\n\n\n\n\nPresentation of Comet\n\n\n\n\n\n\nplatform\n\n\nmachine learning\n\n\ntraining\n\n\n\nWebsite: https://www.comet.com/site/\n\n\n\n\n\n2023-11-08\n\n\nMélanie Gaillochet\n\n\n\n\n\n\n\nPresentation of Synb0-DisCo\n\n\n\n\n\n\nconditional generative network\n\n\ndiffusion magnetic resonance imaging\n\n\ndistortion correction\n\n\necho planar imaging\n\n\nimage synthesis\n\n\n\nDOI: 10.1016/j.mri.2019.05.008\n\n\n\n\n\n2023-11-01\n\n\nSedigheh Dargahi\n\n\n\n\n\n\n\nPresentation of the article ‘Boundary-weighted logit consistency improves calibration of segmentation networks’\n\n\n\n\n\n\ncalibration\n\n\nconsistency regularization\n\n\nsegmentation\n\n\n\nDOI: 10.48550/arXiv.2307.08163\n\n\n\n\n\n2023-10-25\n\n\nSukesh Adiga\n\n\n\n\n\n\n\nPresentation of Vox2Cortex\n\n\n\n\n\n\nreconstruction of cortical surface\n\n\nmagnetic resonance imaging\n\n\ngeometric deep neural network\n\n\n\nDOI: 10.48550/arXiv.2203.09446\n\n\n\n\n\n2023-10-18\n\n\nKaveh Moradkhani\n\n\n\n\n\n\n\nPresentation of DARQ\n\n\n\n\n\n\ndeep learning\n\n\nlinear registration\n\n\nquality control\n\n\n\nDOI: 10.1016/j.neuroimage.2022.119266\n\n\n\n\n\n2023-10-04\n\n\nCharles Bricout\n\n\n\n\n\n\n\nPresentation of the review article ‘Best Practices in Structural Neuroimaging of Neurodevelopmental Disorders’\n\n\n\n\n\n\nchildren\n\n\nfreesurfer\n\n\nneurodevelopmental disorders\n\n\nquality control\n\n\nstructural magnetic resonance imaging\n\n\nstudy design\n\n\n\nDOI: 10.1007/s11065-021-09496-2\n\n\n\n\n\n2023-09-25\n\n\nBenoît Verreman\n\n\n\n\n\n\n\nPresentation of the article ‘Disentangling Human Error from the Ground Truth in Segmentation of Medical Images’\n\n\n\n\n\n\nsupervised learning\n\n\nmedical image segmentation\n\n\nconvolutional neural network\n\n\n\nDOI: 10.48550/arXiv.2007.15963\n\n\n\n\n\n2023-09-20\n\n\nMélanie Gaillochet\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "members/index.html",
    "href": "members/index.html",
    "title": "",
    "section": "",
    "text": "Principal Investigator\n\n\nSylvain Bouix\n   \nProfessor\nDepartment of Software and IT Engineering, ETS, Montréal\nMedical Imaging, Neuroimaging, Neuroinformatics, Anatomical and Diffusion MRI\n\n\nResearch Assistants\n\nBenoît Verreman\n \nResearch assistant\nDepartment of Software and IT Engineering, ETS, Montréal\nNeuroimaging, Neuroinformatics, Anatomical and Diffusion MRI\n\nPhD Students\n\n\n\nKaveh Moradkhani \n   \nGraduate Researcher, Ph.D.\nDepartment of Software and IT Engineering, ETS, Montréal\nComputer Vision, Deep Learning, Medical Imaging, Neuroimaging, Image Processing\n\n\n\n\nSedigheh Dargahi\n\nGraduate Researcher, Ph.D.\nDepartment of Software and IT Engineering, ETS, Montréal\nMedical Imaging, Neuroimaging, Neuroinformatics, Diffusion MRI\n\n\n\nMaster Students\n\n\n\nGhazal Danaee\n  \nGraduate Researcher, M.S.\nDepartment of Software and IT Engineering, ETS, Montréal\nImage processing, Deep learning, Medical image processing, Artificial intelligence\n\n\n\n\nCharles Bricout\n \nGraduate Researcher, M.S.\nDepartment of Software and IT Engineering, ETS, Montréal\nMedical Imaging, Neuroimaging, Computer Vision, Deep Learning\n\n\n\nCollaborators\n Psychiatry Neuroimaging Laboratory, Brigham and Women’s Hospital, Harvard Medical School\n The Center for Morphometric Analysis, Massachusetts General Hospital, Harvard Medical School\n Surgical Planning Laboratory, Brigham and Women’s Hospital, Harvard Medical School\n The Functional Neuroimaging & Bioinformatics Lab, McLean Hospital, Harvard Medical School\n cBRAIN, Ludwig Maximilian University of Munich, Germany\n UNC Biomedical Image Analysis Group, University of North Carolina at Chapel Hill\n The Perk Lab, Queen’s University"
  },
  {
    "objectID": "publications/posts/2023_07_19_Exploring_the_impact_of_hippocampal_sclerosis/index.html",
    "href": "publications/posts/2023_07_19_Exploring_the_impact_of_hippocampal_sclerosis/index.html",
    "title": "Exploring the impact of hippocampal sclerosis on white matter tracts memory in individuals with mesial temporal lobe epilepsy",
    "section": "",
    "text": "Abstract:\nOBJECTIVE: To investigate how the presence/side of hippocampal sclerosis (HS) are related to the white matter structure of cingulum bundle (CB), arcuate fasciculus (AF), and inferior longitudinal fasciculus (ILF) in mesial temporal lobe epilepsy (MTLE).\nMETHODS: We acquired diffusion-weighted magnetic resonance imaging (MRI) from 86 healthy and 71 individuals with MTLE (22 righ-HS; right-HS, 34 left-HS; left-HS, and 15 nonlesional MTLE). We utilized two-tensor tractography and fiber clustering to compare fractional anisotropy (FA) of each side/tract between groups. Additionally, we examined the association between FA and nonverbal (WMS-R) and verbal (WMS-R, RAVLT codification) memory performance for MTLE individuals.\nRESULTS: White matter abnormalities depended on the side and presence of HS. The left-HS demonstrated widespread abnormalities for all tracts, the right-HS showed lower FA for ipsilateral tracts and the nonlesional MTLE group did not differ from healthy individuals. Results indicate no differences in verbal/nonverbal memory performance between the groups, but trend-level associations between higher FA of visual memory and the left CB (r = 0.286, P = 0.018), verbal memory (RAVLT) and -left CB (r = 0.335, P = 0.005), -right CB (r = 0.286, P = 0.016), and -left AF (r = 0.287, P = 0.017).\nSIGNIFICANCE: Our results highlight that the presence and side of HS are crucial to understand the pathophysiology of MTLE. Specifically, left-sided HS seems to be related to widespread bilateral white matter abnormalities. Future longitudinal studies should focus on developing diagnostic and treatment strategies dependent on HS’s presence/side."
  },
  {
    "objectID": "publications/posts/2023_08_21_adverse_outcome_following_mild_traumatic_brain/index.html",
    "href": "publications/posts/2023_08_21_adverse_outcome_following_mild_traumatic_brain/index.html",
    "title": "Adverse Outcome Following Mild Traumatic Brain Injury Is Associated with Microstructure Alterations at the Gray and White Matter Boundary",
    "section": "",
    "text": "Abstract:\nThe gray matter/white matter (GM/WM) boundary of the brain is vulnerable to shear strain associated with mild traumatic brain injury (mTBI). It is, however, unknown whether GM/WM microstructure is associated with long-term outcomes following mTBI. The diffusion and structural MRI data of 278 participants between 18 and 65 years of age with and without military background from the Department of Defense INTRuST study were analyzed. Fractional anisotropy (FA) was extracted at the GM/WM boundary across the brain and for each lobe. Additionally, two conventional analytic approaches were used: whole-brain deep WM FA (TBSS) and whole-brain cortical thickness (FreeSurfer). ANCOVAs were applied to assess differences between the mTBI cohort (n = 147) and the comparison cohort (n = 131). Associations between imaging features and post-concussive symptom severity, and functional and cognitive impairment were investigated using partial correlations while controlling for mental health comorbidities that are particularly common among military cohorts and were present in both the mTBI and comparison group. Findings revealed significantly lower whole-brain and lobe-specific GM/WM boundary FA (p &lt; 0.011), and deep WM FA (p = 0.001) in the mTBI cohort. Whole-brain and lobe-specific GM/WM boundary FA was significantly negatively correlated with post-concussive symptoms (p &lt; 0.039), functional (p &lt; 0.016), and cognitive impairment (p &lt; 0.049). Deep WM FA was associated with functional impairment (p = 0.002). Finally, no significant difference was observed in cortical thickness, nor between cortical thickness and outcome (p &gt; 0.05). Findings from this study suggest that microstructural alterations at the GM/WM boundary may be sensitive markers of adverse long-term outcomes following mTBI."
  },
  {
    "objectID": "presentations/posts/2023_11_15_CB_NeRF/index.html",
    "href": "presentations/posts/2023_11_15_CB_NeRF/index.html",
    "title": "Presentation of NeRF",
    "section": "",
    "text": "Abstract of the article:\nWe present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x,y,z) and viewing direction (θ,ϕ)) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons."
  },
  {
    "objectID": "presentations/posts/2023_10_25_SA_Boundary_weighted_logit_consistency/index.html",
    "href": "presentations/posts/2023_10_25_SA_Boundary_weighted_logit_consistency/index.html",
    "title": "Presentation of the article ‘Boundary-weighted logit consistency improves calibration of segmentation networks’",
    "section": "",
    "text": "Abstract of the article:\nNeural network prediction probabilities and accuracy are often only weakly-correlated. Inherent label ambiguity in training data for image segmentation aggravates such miscalibration. We show that logit consistency across stochastic transformations acts as a spatially varying regularizer that prevents overconfident predictions at pixels with ambiguous labels. Our boundary-weighted extension of this regularizer provides state-of-the-art calibration for prostate and heart MRI segmentation."
  },
  {
    "objectID": "presentations/posts/2024_01_15_SA_Invaratiant_representation_nonparametric_Nadaraya_Watson_head/index.html",
    "href": "presentations/posts/2024_01_15_SA_Invaratiant_representation_nonparametric_Nadaraya_Watson_head/index.html",
    "title": "Presentation of the conference paper ‘Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head’",
    "section": "",
    "text": "Abstract of the article:\nMachine learning models will often fail when deployed in an environment with a data distribution that is different than the training distribution. When multiple environments are available during training, many methods exist that learn representations which are invariant across the different distributions, with the hope that these representations will be transportable to unseen domains. In this work, we present a nonparametric strategy for learning invariant representations based on the recently-proposed Nadaraya-Watson (NW) head. The NW head makes a prediction by comparing the learned representations of the query to the elements of a support set that consists of labeled data. We demonstrate that by manipulating the support set, one can encode different causal assumptions. In particular, restricting the support set to a single environment encourages the model to learn invariant features that do not depend on the environment. We present a causally-motivated setup for our modeling and training strategy and validate on three challenging real-world domain generalization tasks in computer vision."
  },
  {
    "objectID": "presentations/posts/2023_11_08_MG_Comet_platform/index.html",
    "href": "presentations/posts/2023_11_08_MG_Comet_platform/index.html",
    "title": "Presentation of Comet",
    "section": "",
    "text": "Description:\nComet’s machine learning platform integrates with your existing infrastructure and tools so you can manage, visualize, and optimize models—from training runs to production monitoring."
  },
  {
    "objectID": "presentations/posts/2023_10_04_CB_DARQ/index.html",
    "href": "presentations/posts/2023_10_04_CB_DARQ/index.html",
    "title": "Presentation of DARQ",
    "section": "",
    "text": "Abstract of the article:\nLinear registration to stereotaxic space is a common first step in many automated image-processing tools for analysis of human brain MRI scans. This step is crucial for the success of the subsequent image-processing steps. Several well-established algorithms are commonly used in the field of neuroimaging for this task, but none have a 100% success rate. Manual assessment of the registration is commonly used as part of quality control. To reduce the burden of this time-consuming step, we propose Deep Automated Registration Qc (DARQ), a fully automatic quality control method based on deep learning that can replace the human rater and accurately perform quality control assessment for stereotaxic registration of T1w brain scans. In a recently published study from our group comparing linear registration methods, we used a database of 9325 MRI scans and 64476 registrations from several publicly available datasets and applied seven linear registration tools to them. In this study, the resulting images that were assessed and labeled by a human rater are used to train a deep neural network to detect cases when registration failed. We further validated the results on an independent dataset of patients with multiple sclerosis, with manual QC labels available (n=1200). In terms of agreement with a manual rater, our automated QC method was able to achieve 89% accuracy and 85% true negative rate (equivalently 15% false positive rate) in detecting scans that should pass quality control in a balanced cross-validation experiments, and 96.1% accuracy and 95.5% true negative rate (or 4.5% FPR) when evaluated in a balanced independent sample, similar to manual QC rater (test-retest accuracy of 93%). The results show that DARQ is robust, fast, accurate, and generalizable in detecting failure in linear stereotaxic registrations and can substantially reduce QC time (by a factor of 20 or more) when processing large datasets."
  },
  {
    "objectID": "presentations/posts/2023_09_20_MG_disentangling_human_error_from_GT/index.html",
    "href": "presentations/posts/2023_09_20_MG_disentangling_human_error_from_GT/index.html",
    "title": "Presentation of the article ‘Disentangling Human Error from the Ground Truth in Segmentation of Medical Images’",
    "section": "",
    "text": "Abstract of the article:\nRecent years have seen increasing use of supervised learning methods for segmentation tasks. However, the predictive performance of these algorithms depends on the quality of labels. This problem is particularly pertinent in the medical image domain, where both the annotation cost and inter-observer variability are high. In a typical label acquisition process, different human experts provide their estimates of the “true” segmentation labels under the influence of their own biases and competence levels. Treating these noisy labels blindly as the ground truth limits the performance that automatic segmentation algorithms can achieve. In this work, we present a method for jointly learning, from purely noisy observations alone, the reliability of individual annotators and the true segmentation label distributions, using two coupled CNNs. The separation of the two is achieved by encouraging the estimated annotators to be maximally unreliable while achieving high fidelity with the noisy training data. We first define a toy segmentation dataset based on MNIST and study the properties of the proposed algorithm. We then demonstrate the utility of the method on three public medical imaging segmentation datasets with simulated (when necessary) and real diverse annotations: 1) MSLSC (multiple-sclerosis lesions); 2) BraTS (brain tumours); 3) LIDC-IDRI (lung abnormalities). In all cases, our method outperforms competing methods and relevant baselines particularly in cases where the number of annotations is small and the amount of disagreement is large. The experiments also show strong ability to capture the complex spatial characteristics of annotators’ mistakes."
  },
  {
    "objectID": "presentations/posts/2023_11_01_SD_Synthesized_b0_dMRI/index.html",
    "href": "presentations/posts/2023_11_01_SD_Synthesized_b0_dMRI/index.html",
    "title": "Presentation of Synb0-DisCo",
    "section": "",
    "text": "Abstract of the article:\nDiffusion magnetic resonance images typically suffer from spatial distortions due to susceptibility induced off-resonance fields, which may affect the geometric fidelity of the reconstructed volume and cause mismatches with anatomical images. State-of-the art susceptibility correction (for example, FSL’s TOPUP algorithm) typically requires data acquired twice with reverse phase encoding directions, referred to as blip-up blip-down acquisitions, in order to estimate an undistorted volume. Unfortunately, not all imaging protocols include a blip-up blip-down acquisition, and cannot take advantage of the state-of-the art susceptibility and motion correction capabilities. In this study, we aim to enable TOPUP-like processing with historical and/or limited diffusion imaging data that include only a structural image and single blip diffusion image. We utilize deep learning to synthesize an undistorted non-diffusion weighted image from the structural image, and use the non-distorted synthetic image as an anatomical target for distortion correction. We evaluate the efficacy of this approach (named Synb0-DisCo) and show that our distortion correction process results in better matching of the geometry of undistorted anatomical images, reduces variation in diffusion modeling, and is practically equivalent to having both blip-up and blip-down non-diffusion weighted images."
  },
  {
    "objectID": "presentations/posts/2024_01_22_MG_robust_t_loss/index.html",
    "href": "presentations/posts/2024_01_22_MG_robust_t_loss/index.html",
    "title": "Presentation of the article ‘Robust T-Loss for Medical Image Segmentation’",
    "section": "",
    "text": "Abstract of the article:\nThis paper presents a new robust loss function, the T-Loss, for medical image segmentation. The proposed loss is based on the negative log-likelihood of the Student-t distribution and can effectively handle outliers in the data by controlling its sensitivity with a single parameter. This parameter is updated during the backpropagation process, eliminating the need for additional computation or prior information about the level and spread of noisy labels. Our experiments show that the T-Loss outperforms traditional loss functions in terms of dice scores on two public medical datasets for skin lesion and lung segmentation. We also demonstrate the ability of T-Loss to handle different types of simulated label noise, resembling human error. Our results provide strong evidence that the T-Loss is a promising alternative for medical image segmentation where high levels of noise or outliers in the dataset are a typical phenomenon in practice. The project website can be found at https://github.com/Medical-Image-Analysis-Laboratory/fetal_brain_qc/."
  },
  {
    "objectID": "presentations/posts/2023_09_25_BV_Best_practices_sMRI_studies/index.html",
    "href": "presentations/posts/2023_09_25_BV_Best_practices_sMRI_studies/index.html",
    "title": "Presentation of the review article ‘Best Practices in Structural Neuroimaging of Neurodevelopmental Disorders’",
    "section": "",
    "text": "Abstract of the article:\nStructural magnetic resonance imaging (sMRI) offers immense potential for increasing our understanding of how anatomical brain development relates to clinical symptoms and functioning in neurodevelopmental disorders. Clinical developmental sMRI may help identify neurobiological risk factors or markers that may ultimately assist in diagnosis and treatment. However, researchers and clinicians aiming to conduct sMRI studies of neurodevelopmental disorders face several methodological challenges. This review offers hands-on guidelines for clinical developmental sMRI. First, we present brain morphometry metrics and review evidence on typical developmental trajectories throughout adolescence, together with atypical trajectories in selected neurodevelopmental disorders. Next, we discuss challenges and good scientific practices in study design, image acquisition and analysis, and recent options to implement quality control. Finally, we discuss choices related to statistical analysis and interpretation of results. We call for greater completeness and transparency in the reporting of methods to advance understanding of structural brain alterations in neurodevelopmental disorders."
  },
  {
    "objectID": "presentations/posts/2023_10_18_KM_Vox2Cortex/index.html",
    "href": "presentations/posts/2023_10_18_KM_Vox2Cortex/index.html",
    "title": "Presentation of Vox2Cortex",
    "section": "",
    "text": "Abstract of the article:\nThe reconstruction of cortical surfaces from brain magnetic resonance imaging (MRI) scans is essential for quantitative analyses of cortical thickness and sulcal morphology. Although traditional and deep learning-based algorithmic pipelines exist for this purpose, they have two major drawbacks: lengthy runtimes of multiple hours (traditional) or intricate post-processing, such as mesh extraction and topology correction (deep learning-based). In this work, we address both of these issues and propose Vox2Cortex, a deep learning-based algorithm that directly yields topologically correct, three-dimensional meshes of the boundaries of the cortex. Vox2Cortex leverages convolutional and graph convolutional neural networks to deform an initial template to the densely folded geometry of the cortex represented by an input MRI scan. We show in extensive experiments on three brain MRI datasets that our meshes are as accurate as the ones reconstructed by state-of-the-art methods in the field, without the need for time- and resource-intensive post-processing. To accurately reconstruct the tightly folded cortex, we work with meshes containing about 168,000 vertices at test time, scaling deep explicit reconstruction methods to a new level."
  },
  {
    "objectID": "presentations/posts/2023_11_22_BV_FastSurfer_VINN/index.html",
    "href": "presentations/posts/2023_11_22_BV_FastSurfer_VINN/index.html",
    "title": "Presentation of FastSurferVINN",
    "section": "",
    "text": "Abstract of the article:\nLeading neuroimaging studies have pushed 3T MRI acquisition resolutions below 1.0 mm for improved structure definition and morphometry. Yet, only few, time-intensive automated image analysis pipelines have been validated for high-resolution (HiRes) settings. Efficient deep learning approaches, on the other hand, rarely support more than one fixed resolution (usually 1.0 mm). Furthermore, the lack of a standard submillimeter resolution as well as limited availability of diverse HiRes data with sufficient coverage of scanner, age, diseases, or genetic variance poses additional, unsolved challenges for training HiRes networks. Incorporating resolution-independence into deep learning-based segmentation, i.e., the ability to segment images at their native resolution across a range of different voxel sizes, promises to overcome these challenges, yet no such approach currently exists. We now fill this gap by introducing a Voxelsize Independent Neural Network (VINN) for resolution-independent segmentation tasks and present FastSurferVINN, which (i) establishes and implements resolution-independence for deep learning as the first method simultaneously supporting 0.7-1.0 mm whole brain segmentation, (ii) significantly outperforms state-of-the-art methods across resolutions, and (iii) mitigates the data imbalance problem present in HiRes datasets. Overall, internal resolution-independence mutually benefits both HiRes and 1.0 mm MRI segmentation. With our rigorously validated FastSurferVINN we distribute a rapid tool for morphometric neuroimage analysis. The VINN architecture, furthermore, represents an efficient resolution-independent segmentation method for wider application."
  },
  {
    "objectID": "presentations/posts/2024_02_12_GD_Semi_automatic_segmentation/index.html",
    "href": "presentations/posts/2024_02_12_GD_Semi_automatic_segmentation/index.html",
    "title": "Presentation of the article ‘Semi-automatic segmentation of the fetal brain from magnetic resonance imaging’",
    "section": "",
    "text": "Abstract of the article:\nBackground: Volumetric measurements of fetal brain maturation in the third trimester of pregnancy are key predictors of developmental outcomes. Improved understanding of fetal brain development trajectories may aid in identifying and clinically managing at-risk fetuses. Currently, fetal brain structures in magnetic resonance images (MRI) are often manually segmented, which requires both time and expertise. To facilitate the targeting and measurement of brain structures in the fetus, we compared the results of five segmentation methods applied to fetal brain MRI data to gold-standard manual tracings.\nMethods: Adult women with singleton pregnancies (n = 21), of whom five were scanned twice, approximately 3 weeks apart, were recruited [26 total datasets, median gestational age (GA) = 34.8, IQR = 30.9-36.6]. T2-weighted single-shot fast spin echo images of the fetal brain were acquired on 1.5T and 3T MRI scanners. Images were first combined into a single 3D anatomical volume. Next, a trained tracer manually segmented the thalamus, cerebellum, and total cerebral volumes. The manual segmentations were compared with five automatic methods of segmentation available within Advanced Normalization Tools (ANTs) and FMRIB’s Linear Image Registration Tool (FLIRT) toolboxes. The manual and automatic labels were compared using Dice similarity coefficients (DSCs). The DSC values were compared using Friedman’s test for repeated measures.\nResults: Comparing cerebellum and thalamus masks against the manually segmented masks, the median DSC values for ANTs and FLIRT were 0.72 [interquartile range (IQR) = 0.6-0.8] and 0.54 (IQR = 0.4-0.6), respectively. A Friedman’s test indicated that the ANTs registration methods, primarily nonlinear methods, performed better than FLIRT (p &lt; 0.001).\nConclusion: Deformable registration methods provided the most accurate results relative to manual segmentation. Overall, this semi-automatic subcortical segmentation method provides reliable performance to segment subcortical volumes in fetal MR images. This method reduces the costs of manual segmentation, facilitating the measurement of typical and atypical fetal brain development."
  },
  {
    "objectID": "presentations/posts/2024_09_16_GD_multi_atlas_joint_label_fusion/index.html",
    "href": "presentations/posts/2024_09_16_GD_multi_atlas_joint_label_fusion/index.html",
    "title": "Presentation of the article ‘Multi-Atlas Segmentation with Joint Label Fusion’",
    "section": "",
    "text": "Abstract of the article:\nMulti-atlas segmentation is an effective approach for automatically labeling objects of interest in biomedical images. In this approach, multiple expert-segmented example images, called atlases, are registered to a target image, and deformed atlas segmentations are combined using label fusion. Among the proposed label fusion strategies, weighted voting with spatially varying weight distributions derived from atlas-target intensity similarity have been particularly successful. However, one limitation of these strategies is that the weights are computed independently for each atlas, without taking into account the fact that different atlases may produce similar label errors. To address this limitation, we propose a new solution for the label fusion problem in which weighted voting is formulated in terms of minimizing the total expectation of labeling error and in which pairwise dependency between atlases is explicitly modeled as the joint probability of two atlases making a segmentation error at a voxel. This probability is approximated using intensity similarity between a pair of atlases and the target image in the neighborhood of each voxel. We validate our method in two medical image segmentation problems: hippocampus segmentation and hippocampus subfield segmentation in magnetic resonance (MR) images. For both problems, we show consistent and significant improvement over label fusion strategies that assign atlas weights independently."
  },
  {
    "objectID": "presentations/posts/2024_05_06_GD_SimpleClick/index.html",
    "href": "presentations/posts/2024_05_06_GD_SimpleClick/index.html",
    "title": "Presentation of SimpleClick",
    "section": "",
    "text": "Abstract of the article:\nClick-based interactive image segmentation aims at extracting objects with a limited user clicking. A hierarchical backbone is the de-facto architecture for current methods. Recently, the plain, non-hierarchical Vision Transformer (ViT) has emerged as a competitive backbone for dense prediction tasks. This design allows the original ViT to be a foundation model that can be finetuned for downstream tasks without redesigning a hierarchical backbone for pretraining. Although this design is simple and has been proven effective, it has not yet been explored for interactive image segmentation. To fill this gap, we propose SimpleClick, the first interactive segmentation method that leverages a plain backbone. Based on the plain backbone, we introduce a symmetric patch embedding layer that encodes clicks into the backbone with minor modifications to the backbone itself. With the plain backbone pretrained as a masked autoencoder (MAE), SimpleClick achieves state-of-the-art performance. Remarkably, our method achieves 4.15 NoC@90 on SBD, improving 21.8% over the previous best result. Extensive evaluation on medical images demonstrates the generalizability of our method. We further develop an extremely tiny ViT backbone for SimpleClick and provide a detailed computational analysis, highlighting its suitability as a practical annotation tool."
  },
  {
    "objectID": "presentations/posts/2024_01_29_CB_Torchio/index.html",
    "href": "presentations/posts/2024_01_29_CB_Torchio/index.html",
    "title": "Presentation of the python library TorchIO",
    "section": "",
    "text": "Description:\nTorchIO is an open-source Python library for efficient loading, preprocessing, augmentation and patch-based sampling of 3D medical images in deep learning, following the design of PyTorch.\nIt includes multiple intensity and spatial transforms for data augmentation and preprocessing. These transforms include typical computer vision operations such as random affine transformations and also domain-specific ones such as simulation of intensity artifacts due to MRI magnetic field inhomogeneity (bias) or k-space motion artifacts.\nTorchIO is part of the official PyTorch Ecosystem, and was featured at the PyTorch Ecosystem Day 2021 and the PyTorch Developer Day 2021.\nMany groups have used TorchIO for their research. The complete list of citations is available on Google Scholar, and the dependents list is available on GitHub.\nThe code is available on GitHub. If you like TorchIO, please go to the repository and star it!"
  }
]